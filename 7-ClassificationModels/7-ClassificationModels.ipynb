{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed8fa137",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<br/>\n",
    "<img src=\"images/cd-logo-blue-600x600.png\" alt=\"\" width=\"130px\" align=\"left\"/>\n",
    "<img src=\"images/cd-logo-blue-600x600.png\" alt=\"\" width=\"130px\" align=\"right\"/>\n",
    "<div align=\"center\">\n",
    "<h2>Bootcamp Data Science - Módulo 2</h2><br/>\n",
    "<h1>Modelos de clasificación</h1>\n",
    "<br/><br/>\n",
    "    <b>Instructor Principal:</b> Patricio Olivares polivares@codingdojo.cl <br/>\n",
    "    <b>Instructor Asistente:</b> Jesús Ortiz jortiz@codingdojo.cl<br/><br/>\n",
    "    <b>Coding Dojo</b>\n",
    "</div>\n",
    "<br>\n",
    "Fuente: \"Hands-on Machine Learning with Scikit-Learn, Keras & TensorFlow\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a206f4",
   "metadata": {},
   "source": [
    "# Modelos de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630c6066",
   "metadata": {},
   "source": [
    "- Así como los modelos de regresión aprenden a predecir valores, los modelos de clasificación son aquellos enfocados en la **predicción de clases**.\n",
    "- Algunos modelos de clasificación:\n",
    "    * Decision Trees\n",
    "    * Random Forest \n",
    "    * KNN\n",
    "    * Regresión Logística\n",
    "    * Naive Bayes\n",
    "    * Redes Neuronales\n",
    "    * Etc.\n",
    "- Nota como muchos de los modelos ya aprendidos para regresión también pueden ser utilizados para clasificación (con leves modificaciones)\n",
    "- A diferencia de los modelos de regresión, en los modelos de clasificación es importante tener en cuenta la cantidad de datos para cada clase. Tener exceso de una clase respecto a otra puede generar graves problemas en el proceso de aprendizaje (aprender mucho mejor de aquella clase que existan más datos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5a0fe",
   "metadata": {},
   "source": [
    "# Tipos de modelos de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea529557",
   "metadata": {},
   "source": [
    "Los modelos de clasificación pueden ser de tipo\n",
    "- **Clasificación binaria**: El modelo solo debe predecir entre dos posibles clases\n",
    "- **Clasificación multiclase**: El modelo debe predecir entre múltiples posibles clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01aecd2",
   "metadata": {},
   "source": [
    "# Árboles de decisión para clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b5c221",
   "metadata": {},
   "source": [
    "- A diferencia de los árboles de decisión para problemas de regresión, donde la función de costo dependía directamente del *MSE*, al utilizarlo en problemas de clasificación, la función de costo dependerá de una función de *impureza* llamada **Impureza Gini**.\n",
    "- En este caso se opera dividiendo el dataset de entrenamiento en dos grupos en base a una característica $k$ y un umbral $t_k$ tales que $k$ y $t_k$ produzcan el menor grado de impureza.\n",
    "- Ejemplo de cálculo de la impureza de Gini:\n",
    "\n",
    "$$ G_i = 1 - \\sum_{k=1}^n p_{i,k}^2 = 1 - \\left(\\frac{0}{54}\\right)^2 + \\left(\\frac{49}{54}\\right)^2 + \\left(\\frac{5}{54}\\right)^2 \\approx 0.168$$\n",
    "\n",
    "$p_{i,k}$ es la razón entre instancias de clase $k$ vs instancias del nodo $i$ (revisar *value*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f099ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2: ] # Solo columnas de largo y ancho del pétalo\n",
    "y = iris.target\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4eab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4157959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando árbol de decisión\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(100,100))\n",
    "tree.plot_tree(\n",
    "    tree_clf,\n",
    "    feature_names=iris.feature_names[2:],\n",
    "    class_names=iris.target_names,\n",
    "    rounded=True,\n",
    "    filled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5c1f3",
   "metadata": {},
   "source": [
    "- A partir del árbol de decisión es posible obtener la probabilidad de que una nueva instancia pertenezca a una cierta clase.\n",
    "- La nueva instancia pertenecerá a aquella clase con mayor probabilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde03641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nueva instancia\n",
    "x_new = [[5, 1.5]]\n",
    "# Probabilidades por cada clase\n",
    "print(tree_clf.predict_proba(x_new))\n",
    "# Clase predicha\n",
    "print(\"Esta instancia pertenece a la clase\",tree_clf.predict(x_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b52f2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# KNN - K Nearest Neighbors (K Vecinos más próximos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f5679",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- Modelo basado en instancias y uno de los algoritmos de ML más simples de implementar.\n",
    "- Permite clasificación y regresión de datos.\n",
    "- Una nueva instancia se asigna como perteneciente a la clase con las k instancias más cercanas a esta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf5fd5f",
   "metadata": {},
   "source": [
    "<img src=\"images/KnnClassification.png\" alt=\"\" width=\"300px\" align=\"center\"/>\n",
    "Fuente imagen: https://commons.wikimedia.org/wiki/File:KnnClassification.svg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ff0909",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# KNN con Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6dd7c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c00f4",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['target']) # Separación de las características\n",
    "y = df['target'] # Separación del target (corresponde a lo que quiero predecir)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) # Ojo: escalamiento de test se hace en base al train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd7b91",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train) # Ojo: fit en base a los de entrenamiento!!\n",
    "predictions = knn.predict(X_test)\n",
    "print(predictions.tolist())\n",
    "print(y_test.tolist())\n",
    "print('Accuracy:',knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8773da6f",
   "metadata": {},
   "source": [
    "# Regresión Logística (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb85d678",
   "metadata": {},
   "source": [
    "- **Contexto**: Intentemos utilizar la regresión lineal como un clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ea5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Set de datos sobre datos de cancer de mamas en Wisconsin \n",
    "# Objetivo: clasificación de tumores benignos y malignos\n",
    "br_cancer = load_breast_cancer()\n",
    "print('Características', br_cancer.feature_names)\n",
    "# Originalmente 0 es maligno y 1 es benigno. Lo invertiremos\n",
    "print('Target', br_cancer.target_names[::-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b29be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = br_cancer.data[:, 0].reshape(-1,1) # mean_radius\n",
    "y = 1 - br_cancer.target # Nuevamente inversión maligno/benigno 0/1\n",
    "# Luego de inversión: benigno 0 y maligno 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "\n",
    "plt.plot(X_train, y_train,'bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando modelo de regresión lineal\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Entrenamiento regresor lineal\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "print('Intercepto:', lin_reg.intercept_, )\n",
    "print('Coeficientes:', lin_reg.coef_ )\n",
    "\n",
    "# Gráfico datos reales test vs predicciones de test\n",
    "plt.plot(X_test, y_test,'bo')\n",
    "plt.plot(X_test, lin_reg.predict(X_test),'r.')\n",
    "plt.xlabel('Radio promedio tumor')\n",
    "plt.ylabel('Tipo tumor 0/benigno 1/maligno')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c5936a",
   "metadata": {},
   "source": [
    "- Regresión lineal simplemente hace regresión sobre los datos. ¿Cómo podemos clasificar usando este modelo? \n",
    "    - R: *umbral*\n",
    "    \n",
    "\\begin{align}\n",
    "    \\hat{y}=\\left\\{\n",
    "    \\begin{array}{ll}\n",
    "      0, & \\mbox{si $\\hat{p} <0.5$}.\\\\\n",
    "      1, & \\mbox{si $\\hat{p} \\geq0.5$}.\n",
    "    \\end{array}\n",
    "  \\right.\n",
    "\\end{align}\n",
    "\n",
    "donde $\\hat{p}$ es el valor predicho por el regresor lineal e $\\hat{y}$ es la clase predicha. En este ejemplo, escogeremos el umbral en 0.5 para clasificación\n",
    "- Problema: ¿Cómo interpretamos los valores de la regresión lineal? por ejemplo  $\\hat{p}=-0.25$\n",
    "- La regresión logística hace la regresión lineal **interpretable**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992cc382",
   "metadata": {},
   "source": [
    "### Regresión logística\n",
    "\n",
    "- A pesar de hacer regresión, se utiliza normalmente para clasificación\n",
    "- Permite darle una interpretación a los valores obtenidos por la regresión: Probabilidad de pertenecer a cierta clase\n",
    "- Ecuación de función logística\n",
    "\n",
    "$$ \\sigma(t) = \\frac{1}{1+e^{-t}} = \\frac{1}{1+\\frac{1}{e^t}}$$\n",
    "\n",
    "<img src='images/logisticFunction.png' width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d091fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Entrenamiento regresión logística\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Gráfico datos reales test vs predicciones de test\n",
    "plt.plot(X_test, y_test,'bo')\n",
    "plt.plot(X_test, log_reg.predict(X_test), 'ro', alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d617c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(\"Predicción de regresión logística\", log_reg.predict(X_test))\n",
    "print(\"Valor target real\", y_test)\n",
    "print(log_reg.predict_proba(X_test))\n",
    "print(np.sum(log_reg.predict_proba(X_test),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b700881",
   "metadata": {},
   "source": [
    "# Recordatorio: Tipos de errores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5757de87",
   "metadata": {},
   "source": [
    "- **Errores de Tipo 1 - Falso Positivo**: Clasificamos un elemento como *perteneciente* (positivo) a la clase **incorrectamente** (falso)\n",
    "\n",
    "<img src=\"images/un5.jpeg\" alt=\"\" width=\"300px\" align=\"center\"/>\n",
    "\n",
    "- **Errores de Tipo 2 - Falso Negativo**: Clasificamos un elemento como *no perteneciente* (negativo) a la clase **incorrectamente** (falso)\n",
    "\n",
    "<img src=\"images/noUn5.jpeg\" alt=\"\" width=\"300px\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c4c5c0",
   "metadata": {},
   "source": [
    "# Recordatorio: Matriz de confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6301553",
   "metadata": {},
   "source": [
    "- **Matriz de confusión**: Permite contar la cantidad de veces que instancias de la clase A son clasificadas como clase B\n",
    "<img src=\"images/matrizConfusion.png\" alt=\"\" width=\"700px\" align=\"center\"/>\n",
    "Fuente: \"Hands-on Machine Learning with Scikit-Learn, Keras & Tensorflow\", O'Reilly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adca5407",
   "metadata": {},
   "source": [
    "# Recordatorio: métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5190f11",
   "metadata": {},
   "source": [
    "- **True Positive Rate** (sensibilidad)\n",
    "\n",
    "$$ TPR = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "- **False Positive Rate** \n",
    "$$ FPR = \\frac{FP}{FP + TN} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c9c89",
   "metadata": {},
   "source": [
    "# Curvas ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f33d711",
   "metadata": {},
   "source": [
    "- La curva **Característica Operativa del Receptor** (Receiver Operative Characteristic/ROC) muestra la relación entre el True Positive Rate (sensibilidad) y el False Positive Rate. (Visualización [aquí](http://www.navan.name/roc/))\n",
    "- El **Área Bajo la Curva** (Area Under Curve/AUC) se utiliza como un valor de medida que proyecta lo visualizado en la curva ROC. Un clasificador perfecto tendrá valor $AUC=1$, mientras que para un clasificador aleatorio, $AUC=0.5$. En scikit-learn, para que se pueda calcular el auc_score de un modelo, este **debe** tener el método *predict_proba* (Ej. El modelo Ridge, no posee este método, por lo que no sería posible calcular el auc_score de este)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa44ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve\n",
    "\n",
    "# Set de datos de flores con solo 2 clases en vez de 3\n",
    "df = pd.read_csv('data/modifiedIris2Classes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4414d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2af207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Dividir en X e y\n",
    "X = df.drop(columns = 'target')\n",
    "y = df['target']\n",
    "# Crea una instancia del modelo\n",
    "logreg = LogisticRegression()\n",
    "# División entrenamiento prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Escalar la regresión logística\n",
    "scaler = StandardScaler()\n",
    "# Ajustar solo al conjunto de entrenamiento\n",
    "scaler.fit(X_train)\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Entrenamiento del modelo con los datos, almacenando la información aprendida de los datos\n",
    "# Model está aprendiendo la relación entre X e y\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a7fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la curva ROC\n",
    "plot_roc_curve(logreg, X_test, y_test)\n",
    "plt.plot([0, 1], [0, 1], ls = '--', label = 'Baseline (AUC = 0.5)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b022fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el AUC para conjuntos de entrenamiento y prueba\n",
    "print(f'Training AUC: {roc_auc_score(y_train, logreg.predict_proba(X_train)[:,1])}')\n",
    "print(f'Testing AUC: {roc_auc_score(y_test, logreg.predict_proba(X_test)[:,1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba112c3",
   "metadata": {},
   "source": [
    "# Clasificación multiclase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34967ae0",
   "metadata": {},
   "source": [
    "- Hasta ahora hemos estudiado clasificadores binarios: solo son capaces de distinguir entre dos clases.\n",
    "- Es posible extender algoritmos binarios para poder identificar múltiples clases\n",
    "- Estrategias:\n",
    "    - Uno contra Todos (One versus All/One versus the Rest) (OvA/OvR)\n",
    "    - Uno contra Uno (One versus One) (OvO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e7f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando dataset MNIST para clasificación multiclase\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data # Ojo, en scikit learn, ya vienen los datos en formato fila!!\n",
    "y = digits.target\n",
    "\n",
    "\n",
    "# Ejemplos de datos\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "fig = plt.figure(dpi=300)\n",
    "fig.suptitle('Algunos ejemplos de MNIST')\n",
    "\n",
    "ax = []\n",
    "rand_numbers = np.random.choice(len(y), 9, replace=False)\n",
    "for i in range(0,9):\n",
    "    ax.append(fig.add_subplot(3,3,i+1))\n",
    "    ax[i].imshow(X[rand_numbers[i]].reshape(8,8), cmap='gray')\n",
    "    ax[i].title.set_text(f'Número {y[rand_numbers[i]]}')\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9277750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "log_reg = LogisticRegression(solver='liblinear',\n",
    "                            multi_class='ovr')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy test: ', log_reg.score(X_test,y_test))\n",
    "print('Valores reales', y_test)\n",
    "print('Predicciones:',log_reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e69bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Ejemplos de predicciones\n",
    "# i = 20\n",
    "i = 11 # Error de predicción\n",
    "\n",
    "image = X_test[i].reshape(8,8)\n",
    "plt.imshow(image,cmap='gray')\n",
    "print('Valor real', y_test[i])\n",
    "print('Predicción', log_reg.predict(X_test[i].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba661a96",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Actividad 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847f5ef",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "A partir del dataset de supervivencia del titanic, disponible [aquí](data/titanic.csv)\n",
    "- Utilice los algoritmos de clasificación aprendidos para predecir la supervivencia de los pasajeros.\n",
    "- Obtenga y compare la curva ROC para cada clasificador utilizado."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
